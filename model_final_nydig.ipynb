{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "####constructing daily yield table for target ticker and raw pairs\n",
    "class DailyPortfolio:\n",
    "    def __init__(self,raw_price_table,target_ticker=\"TSLA\"):\n",
    "        self.raw_price_table = raw_price_table\n",
    "        self.target_ticker = target_ticker\n",
    "        self.target_history = self.get_ticker_price()\n",
    "        self.price_table = self.merge_price()\n",
    "        self.yield_table = self.generate_yield()\n",
    "        self.spec_list = {}\n",
    "    \n",
    "    def get_ticker_price(self):\n",
    "        target = yf.Ticker(self.target_ticker)\n",
    "        target_history = target.history(period=\"max\")\n",
    "        return target_history\n",
    "        \n",
    "    def merge_price(self):\n",
    "        price_table = pd.concat([self.raw_price_table,self.target_history['Close']],join=\"inner\",axis=1)\n",
    "        return price_table\n",
    "\n",
    "    def generate_yield(self):\n",
    "        yield_table = self.price_table/self.price_table.shift(periods=1)-1\n",
    "        yield_table.replace([np.inf, -np.inf], np.nan)\n",
    "        return yield_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####create date-related variables#############################\n",
    "####start_date=start date of the data \n",
    "####end_date=end date of the data\n",
    "####port_date=start date for the portfolio prediction\n",
    "####min_obs_ratio= if set 30%, raw_pair which has more than 30% of non-na yield value will be included in prediction\n",
    "####set the training set date range and testing set date range -> the modle will initially be trained on x1-xt and y1-yt\n",
    "####then tested by using x_{t+1} and y_{t+1}\n",
    "class DateVar(DailyPortfolio):  \n",
    "    def __init__(self,dailyportfol,**kwargs):\n",
    "\n",
    "        start_date = pd.Timestamp(kwargs.get(\"start_date\",dailyportfol.yield_table.index[1]))\n",
    "        end_date = pd.Timestamp(kwargs.get(\"end_date\",dailyportfol.yield_table.index[(dailyportfol.yield_table.shape[0]-1)]))\n",
    "        dep_var = kwargs.get(\"dep_var\",'Close')\n",
    "        min_obs_ratio = kwargs.get(\"min_obs_ratio\",0.7)        \n",
    "\n",
    "        if \"port_date\" in list(kwargs.keys()):\n",
    "            port_date = kwargs.get(\"port_date\")\n",
    "            port_date = pd.Timestamp(port_date)\n",
    "            port_date_yesterday = pd.date_range(port_date,port_date)\n",
    "            port_date_yesterday = port_date_yesterday.shift(-1,freq=\"D\")\n",
    "            port_date_yesterday = port_date_yesterday[0]\n",
    "        else:\n",
    "            port_date = dailyportfol.yield_table.index[round(dailyportfol.yield_table.shape[0]*0.7)]\n",
    "            port_date_yesterday = port_date.shift(-1,freq=\"D\")\n",
    "            \n",
    "        ini_train_index = pd.date_range(start_date,port_date_yesterday).intersection(dailyportfol.yield_table.index)\n",
    "        ini_test_index = pd.date_range(port_date,end_date).intersection(dailyportfol.yield_table.index)\n",
    "        \n",
    "        self.ini_train_index = ini_train_index\n",
    "        self.ini_test_index = ini_test_index\n",
    "        self.start_date = start_date.strftime(r'%Y%m%d')\n",
    "        self.end_date = end_date.strftime(r'%Y%m%d')\n",
    "        self.port_date = port_date.strftime(r'%Y%m%d')\n",
    "\n",
    "\n",
    "        clean_yield_table = dailyportfol.yield_table.copy()\n",
    "        clean_yield_table = clean_yield_table.fillna(0)\n",
    "        clean_yield_table = clean_yield_table.loc[self.ini_train_index.append(self.ini_test_index)]\n",
    "        \n",
    "        n_min_obs = round(clean_yield_table.shape[0]*min_obs_ratio)\n",
    "        X_table = clean_yield_table.loc[:,(clean_yield_table!=0).apply(np.sum,0) > n_min_obs]\n",
    "        Y_table = X_table.loc[:,[dep_var]].copy()\n",
    "        X_table = X_table.drop([dep_var],axis=1)\n",
    "\n",
    "        self.X_table = X_table\n",
    "        self.Y_table = Y_table\n",
    "        self.dep_var = dep_var\n",
    "        self.ind_var = list(X_table.columns)\n",
    "        self.min_obs_ratio = min_obs_ratio\n",
    "\n",
    "    def generate_index(self,tt_index):\n",
    "        ini_train_index = tt_index[0]\n",
    "        ini_test_index = tt_index[1]\n",
    "        est_index = ini_train_index\n",
    "        pred_index = ini_test_index[0:1]\n",
    "        left_pred_index = ini_test_index.drop(pred_index)\n",
    "        ret = [(est_index, pred_index)]\n",
    "\n",
    "        while len(left_pred_index)>0:\n",
    "            est_index=est_index.append(pred_index)\n",
    "            pred_index = left_pred_index[0:1]\n",
    "            left_pred_index = left_pred_index.drop(pred_index)\n",
    "            ret.append((est_index, pred_index))  \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########fit the model with l2 norm in the objective function############\n",
    "#est_data: dataset to be used for model estimation\n",
    "#pred_data: dataset to be used for prediction \n",
    "#W1_B_tilde_old: parameter estimates of the previous estimation (weight of each currency in the portfolio from the previous estimation)\n",
    "#lambda_l: learning_rate\n",
    "#lambda_b: L2 regularization\n",
    "#lambda_o: regularziation to reduce the transaction costs\n",
    "class ModelFit(DateVar):\n",
    "    def __init__(self,datev,**kwargs):\n",
    "        \n",
    "        sep_tt_index = kwargs.get(\"sep_tt_index\",None)\n",
    "        lambda_l = kwargs.get(\"lambda_l\",0.01)\n",
    "        lambda_b = kwargs.get(\"lambda_b\",0.001)\n",
    "        lambda_o = kwargs.get(\"lambda_o\",0.001)\n",
    "        epsilon = kwargs.get(\"epsilon\",2.220446e-16)\n",
    "        \n",
    "        ret1 = []\n",
    "        ret2 = []\n",
    "        ret3 = []\n",
    "        ret4 = []\n",
    "        ret5 = pd.DataFrame()\n",
    "        pred_index_list = []\n",
    "        y_true = []\n",
    "\n",
    "        if sep_tt_index is None:\n",
    "            iterates = self.generate_index([datev.ini_train_index, datev.ini_test_index])\n",
    "            port_date = datev.port_date\n",
    "            ###print (port_date)\n",
    "        else:\n",
    "            iterates = self.generate_index(sep_tt_index)\n",
    "            port_date = str(sep_tt_index[1][0].strftime(r'%Y%m%d'))\n",
    "\n",
    "        for est_index, pred_index in iterates:\n",
    "            X_est, Y_est = datev.X_table.loc[est_index], datev.Y_table.loc[est_index]\n",
    "            X_pred, Y_pred = datev.X_table.loc[pred_index], datev.Y_table.loc[pred_index]\n",
    "            pred_index_list.append(str(pred_index[0].strftime(r'%Y%m%d')))\n",
    "            y_true.append(Y_pred.iloc[0,0])\n",
    "\n",
    "            if port_date == str(pred_index[0].strftime(r'%Y%m%d')):\n",
    "                daily_fit_result = self.fit(est_data = {\"X\":X_est,\"Y\":Y_est}, pred_data = {'X':X_pred, 'Y':Y_pred})\n",
    "            else:\n",
    "                daily_fit_result = self.fit(est_data = {\"X\":X_est,\"Y\":Y_est}, pred_data = {'X':X_pred, 'Y':Y_pred},W1_B_tilde_old=W1_B_tilde_old)\n",
    "\n",
    "            ret1.append(daily_fit_result)\n",
    "            ret2.append(daily_fit_result['MSE_est_ml'].iloc[0,0])\n",
    "            ret3.append(daily_fit_result['MSE_pred_ml'].iloc[0,0])\n",
    "            ret4.append(daily_fit_result['Y_pred_ml'].iloc[0,0])\n",
    "            ret5 = pd.concat([ret5,daily_fit_result['W1_B_tilde']],axis=1)\n",
    "            W1_B_tilde_old = daily_fit_result['W1_B_tilde']\n",
    "\n",
    "        ret5.columns=pred_index_list\n",
    "        ret5.index = X_est.columns\n",
    "\n",
    "        self.all_results = ret1\n",
    "        self.MSE_est = ret2\n",
    "        self.MSE_pred = ret3\n",
    "        self.y_pred = ret4\n",
    "        self.y_true = y_true\n",
    "        self.weights = ret5\n",
    "\n",
    "    def fit(self,est_data,pred_data=None,W1_B_tilde_old=None,**kwargs):\n",
    "        \n",
    "        lambda_l = kwargs.get(\"lambda_l\",0.01)\n",
    "        lambda_b = kwargs.get(\"lambda_b\",0.000001)\n",
    "        lambda_o = kwargs.get(\"lambda_o\",0.001)\n",
    "        epsilon = kwargs.get(\"epsilon\",2.220446e-16)\n",
    "\n",
    "        if W1_B_tilde_old is None:\n",
    "            initial_fit = True\n",
    "            W1_B_tilde_old = 0.0\n",
    "        else:\n",
    "            initial_fit = False\n",
    "        \n",
    "        X_est = est_data['X']\n",
    "        Y_est = est_data['Y']\n",
    "\n",
    "        n_input = X_est.shape[1]\n",
    "\n",
    "        Y_B = tf.placeholder(\"float\")\n",
    "        X_B = tf.placeholder(\"float\", [None, n_input])\n",
    "        W1_B_tilde_old_input = tf.placeholder(\"float\")\n",
    "\n",
    "        W1_B = tf.Variable(tf.random_normal( [n_input, 1] )) \n",
    "        W1_B_denom = tf.math.reduce_sum(tf.math.exp(W1_B))\n",
    "        W1_B_tilde = tf.math.exp(W1_B)/W1_B_denom\n",
    "        Y_hat = tf.matmul(X_B, W1_B_tilde)\n",
    "        cost = tf.reduce_mean(tf.square(Y_hat - Y_B)) + \\\n",
    "               lambda_b * tf.reduce_mean(tf.square(W1_B)) + \\\n",
    "               tf.dtypes.cast(initial_fit==False,dtype=tf.float32) * lambda_o * tf.reduce_mean(tf.square(W1_B_tilde-W1_B_tilde_old))    \n",
    "\n",
    "        generator = tf.train.AdamOptimizer(learning_rate = lambda_l)\n",
    "        optimizer = generator.minimize(cost)\n",
    "\n",
    "        init = tf.global_variables_initializer()\n",
    "        session = tf.Session()\n",
    "        session.run(init)\n",
    "\n",
    "        \n",
    "        feed_dict = {X_B:X_est, Y_B:Y_est, W1_B_tilde_old_input:W1_B_tilde_old}\n",
    "        \n",
    "        last_cost = np.Inf\n",
    "        cost_all = None\n",
    "        n_iter = 0\n",
    "\n",
    "        cost_all = []\n",
    "        while True:\n",
    "            session.run(optimizer, feed_dict = feed_dict)\n",
    "            current_cost = session.run(cost, feed_dict = feed_dict)\n",
    "            cost_all.append(current_cost)\n",
    "            if (last_cost - current_cost) < epsilon:\n",
    "                break\n",
    "            last_cost = current_cost\n",
    "            n_iter += 1\n",
    "            if n_iter > 30000:\n",
    "                break\n",
    "        \n",
    "        Y_est_ml = session.run(Y_hat,feed_dict)\n",
    "        MSE_est_ml = np.mean((Y_est_ml - Y_est)**2)##MSE for training (estimation) set\n",
    "\n",
    "        if pred_data is None:\n",
    "            Y_pred_ml = None\n",
    "            MSE_pred_ml = None\n",
    "        else:\n",
    "            X_pred = pred_data['X']\n",
    "            Y_pred = pred_data['Y']\n",
    "            Y_pred_ml = session.run(Y_hat,{X_B:X_pred, Y_B:Y_pred})\n",
    "            MSE_pred_ml = np.mean((Y_pred_ml - Y_pred)**2)###MSE for testing (prediction) set \n",
    "        \n",
    "        t_W1_B = session.run(W1_B,feed_dict)\n",
    "        t_W1_B_tilde = session.run(W1_B_tilde,feed_dict)\n",
    "        \n",
    "        ret = {\"W1_B\":pd.DataFrame(t_W1_B), \"W1_B_tilde\":pd.DataFrame(t_W1_B_tilde), \n",
    "        \"Y_est_ml\":pd.DataFrame(Y_est_ml), \"MSE_est_ml\":pd.DataFrame(MSE_est_ml),   \n",
    "        \"Y_pred_ml\":pd.DataFrame(Y_pred_ml), \"MSE_pred_ml\":pd.DataFrame(MSE_pred_ml) \n",
    "        }\n",
    "\n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class OptHyper(DateVar):\n",
    "    def __init__(self,datev,**kwargs):\n",
    "        \n",
    "        lambda_l_list = kwargs.get(\"lambda_l_list\",list(10.0**(-np.arange(1,3,1))))\n",
    "        lambda_b_list = kwargs.get(\"lambda_b_list\",list(10.0**(-np.arange(0,2,1))))\n",
    "        lambda_o_list = kwargs.get(\"lambda_o_list\",list(10.0**(-np.arange(0,2,1))))\n",
    "        val_ratio = kwargs.get(\"val_ratio\",0.01)\n",
    "\n",
    "        X_train = datev.X_table.loc[datev.ini_train_index]\n",
    "        Y_train = datev.Y_table.loc[datev.ini_train_index]\n",
    "\n",
    "        hyper_param_list = [(lambda_l,lambda_b,lambda_o) for lambda_l in lambda_l_list for lambda_b in lambda_b_list for lambda_o in lambda_o_list]\n",
    "        \n",
    "        ######for hyperparameter optimization, initial training set is devided into 2: 99% & 1%\n",
    "        start_date = datev.ini_train_index[0]\n",
    "        end_date = datev.ini_train_index[-1]\n",
    "        port_date = datev.ini_train_index[round(len(datev.ini_train_index)*(1-val_ratio))]\n",
    "        port_date_yesterday = pd.date_range(port_date,port_date)\n",
    "        port_date_yesterday = port_date_yesterday.shift(-1,freq=\"D\")\n",
    "        port_date_yesterday = port_date_yesterday[0]\n",
    "\n",
    "        est_index = pd.date_range(start_date,port_date_yesterday).intersection(datev.ini_train_index)\n",
    "        pred_index = pd.date_range(port_date,end_date).intersection(datev.ini_train_index)\n",
    "        \n",
    "        ret = []\n",
    "        for hyper_param in hyper_param_list:\n",
    "            ret.append(ModelFit(datev,sep_tt_index=[est_index, pred_index],lambda_l=hyper_param[0],lambda_b=hyper_param[1],lambda_o=hyper_param[2]))\n",
    "        \n",
    "        total_MSE_pred = [np.mean(x.MSE_pred) for x in ret]\n",
    "        #####optimal hyper-parameter is the hyperparameter set with minimum total_MSE_pred\n",
    "        opt_hyper_param = hyper_param_list[total_MSE_pred.index(min(total_MSE_pred))]\n",
    "        self.all_results = ret\n",
    "        self.total_MSE_pred = total_MSE_pred\n",
    "        self.opt_hyper_param = opt_hyper_param\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "p368",
   "language": "python",
   "name": "p368"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
